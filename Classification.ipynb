{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwKLLCrm3cM2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
      ],
      "metadata": {
        "id": "dTMVu7yi3fyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_df.schema[\"label\"].dataType"
      ],
      "metadata": {
        "id": "BXUKnYOd3hVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "train_df, test_df = labeled_df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "9OlnQMi63i21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index and encode categoricals\n",
        "aisle_indexer = StringIndexer(inputCol=\"aisle_id\", outputCol=\"aisle_index\")\n",
        "dept_indexer  = StringIndexer(inputCol=\"department_id\", outputCol=\"dept_index\")\n",
        "aisle_encoder = OneHotEncoder(inputCol=\"aisle_index\", outputCol=\"aisle_vec\")\n",
        "dept_encoder  = OneHotEncoder(inputCol=\"dept_index\", outputCol=\"dept_vec\")"
      ],
      "metadata": {
        "id": "0v3hjQ-q3kaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble features\n",
        "feature_cols = [\n",
        "    \"avg_cart_position\",\n",
        "    \"total_orders\",\n",
        "    \"total_reorders\",\n",
        "    \"aisle_vec\",\n",
        "    \"dept_vec\"\n",
        "]\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features\"\n",
        ")"
      ],
      "metadata": {
        "id": "e5CEpw_S3mJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create evaluator for AUC (area under ROC curve)\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "\n",
        "# Create evaluator for F1 score\n",
        "f1_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")"
      ],
      "metadata": {
        "id": "J4Vv4tgQ3n3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define logistic regression model\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Create pipeline with preprocessing steps and logistic regression\n",
        "lr_pipeline = Pipeline(stages=[\n",
        "    aisle_indexer,\n",
        "    dept_indexer,\n",
        "    aisle_encoder,\n",
        "    dept_encoder,\n",
        "    assembler,\n",
        "    lr\n",
        "])"
      ],
      "metadata": {
        "id": "oqpUbibp3pZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression pipeline on training data\n",
        "lr_model = lr_pipeline.fit(train_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "lr_predictions = lr_model.transform(test_df)"
      ],
      "metadata": {
        "id": "suh08Ydb3q67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate AUC and F1 score for logistic regression\n",
        "lr_auc = evaluator.evaluate(lr_predictions)\n",
        "lr_f1 = f1_evaluator.evaluate(lr_predictions)\n",
        "\n",
        "print(f\"Logistic Regression AUC: {lr_auc:.4f}\")\n",
        "print(f\"Logistic Regression F1 Score: {lr_f1:.4f}\")"
      ],
      "metadata": {
        "id": "oFDiDsZ13sgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define random forest classifier\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "186_bWQJ3uFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline with preprocessing steps and random forest\n",
        "pipeline = Pipeline(stages=[\n",
        "    aisle_indexer,\n",
        "    dept_indexer,\n",
        "    aisle_encoder,\n",
        "    dept_encoder,\n",
        "    assembler,\n",
        "    rf\n",
        "])"
      ],
      "metadata": {
        "id": "nOB5XbHf3vk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the random forest pipeline on training data\n",
        "model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "y9bN1oTR3xCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_df)"
      ],
      "metadata": {
        "id": "yIBh9vJ83yqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imbalanced so we will use AUC and F1 as evaluation metrics\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC = {rf_auc:.4f}\")\n",
        "\n",
        "rf_f1 = f1_evaluator.evaluate(predictions)\n",
        "print(f\"Test F1 Score: {rf_f1:.4f}\")\n",
        "\n",
        "# Train set metrics\n",
        "train_predictions = model.transform(train_df)\n",
        "print(f\"Train F1 Score: {f1_evaluator.evaluate(train_predictions):.4f}\")\n"
      ],
      "metadata": {
        "id": "RewscWaO30Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the trained Random Forest model from the pipeline\n",
        "rf_model = model.stages[-1]\n",
        "\n",
        "# Get importances\n",
        "importances = rf_model.featureImportances.toArray()\n",
        "\n",
        "# Feature names\n",
        "feature_names = [\"total_orders\", \"total_reorders\", \"avg_cart_position\"] + [\"aisle_vec\", \"dept_vec\"]\n",
        "\n",
        "# Print top features\n",
        "print(\"Feature Importances:\")\n",
        "for name, imp in zip(feature_names, importances):\n",
        "    print(f\"{name:<20} â†’ {imp:.4f}\")\n"
      ],
      "metadata": {
        "id": "VP8Yg-Yr31-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Compute confusion matrix by counting label-prediction pairs in test predictions\n",
        "conf_matrix = (\n",
        "    predictions.groupBy(\"label\", \"prediction\")\n",
        "    .agg(F.count(\"*\").alias(\"count\"))\n",
        "    .orderBy(\"label\", \"prediction\")\n",
        ")\n",
        "\n",
        "conf_matrix.show()\n"
      ],
      "metadata": {
        "id": "ZgmsX5P233sV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}